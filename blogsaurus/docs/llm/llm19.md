---
sidebar_position: 19
---

# [LLM] 19. 파인 튜닝 개요
---

## 파인 튜닝
---

파인튜닝이란 사전 학습된 LLM을 특정 task에 맞게 추가로 학습시키는 과정입니다.
LLM은 대규모 데이터셋에서 학습되어 일반적인 언어 패턴을 이해하지만 특정한 분류 작업을 수행하려면 추가적인 학습이 필요합니다.

### 파인 튜닝 유형

1. Classification Fine-Tuning (분류 파인튜닝)
- 정해진 카테고리 중 하나를 예측하는 작업
- ex: 감성 분석, 스팸필터 등..

2. Instruction Fine-Tuning (명령어 파인튜닝)
- LLM이 특정 명령을 이해하고 원하는 방식으로 답변하도록 훈련
- ex: 챗봇, 고객 지원 등..


### 결론

파인튜닝은 다음과 같은 경우에 필요합니다.
- 모델이 특정 도메인의 데이터를 이해해야할 때 (법, 의료기록)
- 일반적인 LLM보다 높은 성능 필요한 경우


## 파인튜닝 준비방법
---

파인튜닝을 하려면 데이터를 준비해야합니다. 데이터 준비과정은 다음과 같습니다.

1. 데이터 수집  
2. 데이터 전처리  
3. 데이터 나누기 (훈련, 검증, 테스트)
    - 훈련 데이터는 80% : 모델 학습 데이터
    - 검증 데이터는 10% : 학습 중 모델 성능 평가
    - 테스트 데이터는 10% : 최종 성능 평가


## 데이터 로더
---

PyTorch의 `DataLoader`는 대량의 데이터를 효과적으로 처리할 수 있도록 도와줍니다.

학습 과정에서 한 번에 모든 데이터를 메모리에 올릴 수 없기 때문에 배치단위로 데이터를 불러와 모델에 전달하는 방식이 필요합니다.

- 기능
    - 데이터를 배치 단위로 나눠서 모델에 전달
    - 셔플링을 지원하여 학습 성능 향상
    - 병렬처리로 빠르게 데이터 로딩

- 과정
    1. 데이터셋 정의
    2. 데이터 로더 생성
    3. 배치 인덱싱을 위한 collate function 활용


## 사전 학습 모델로 초기화
---

새로운 모델로 학습하는 것은 매우 많은 데이터와 연산 비용이 필요합니다. 사전 학습된 모델을 사용하여 파인튜닝을 하면 다음과 같은 장점이 있습니다.
- 빠른 학습
- 적은 데이터 필요
- 하드웨어 비용 절감
- 일반화 능력 향상


## 분류 헤드
---

사전 학습된 LLM은 기본적으로 언어를 이해하고 생성하는 능력이 있습니다. 특정한 작업을 수행하려면 모델 최상단에 추가적인 학습 가능한 레이어(헤드)를 추가해야합니다.
