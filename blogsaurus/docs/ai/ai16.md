---
sidebar_position: 16
---

# 🚀 Vertex AI로 생성형 AI를 운영하는 방법: MLOps 관점에서 본 백서 해설

생성형 AI는 지금 기술 산업에서 가장 뜨거운 주제 중 하나다. 하지만 놀라운 데모를 넘어, 실제 환경에서 이를 어떻게 **안정적으로 운영**할 수 있을까? 바로 여기에 **MLOps**가 중요한 역할을 한다. Google Cloud의 백서 **“Operationalizing Generative AI on Vertex AI using MLOps”**는 이 질문에 대한 해답을 구체적으로 제시한다.

이 글에서는 해당 백서의 핵심 내용을 정리하며, 생성형 AI 시스템을 실전에서 어떻게 관리하고 최적화할 수 있는지를 소개한다.

---

## 🎯 생성형 AI와 MLOps의 접점

전통적인 소프트웨어 개발의 DevOps처럼, MLOps는 **머신러닝 모델의 라이프사이클**을 관리하는 방법론이다. 하지만 생성형 AI는 기존 ML보다 더 복잡한 문제들을 안고 있다:

- 모델이 매우 크고 복잡하며
- 입력(프롬프트)에 민감하고
- 결과가 비결정적(non-deterministic)이다

따라서, 생성형 AI 시스템에서는 단순한 모델 배포를 넘어서 **프롬프트 관리, 체이닝, 데이터 운영, 평가, 거버넌스**까지 포함하는 **새로운 MLOps 체계**가 필요하다.

---

## 🧭 생성형 AI 시스템의 5단계 운영 전략

백서는 생성형 AI 애플리케이션을 다음과 같은 **5단계 라이프사이클**로 나눈다:

1. **Discover**: 적절한 모델 탐색
2. **Develop & Experiment**: 프롬프트 설계 및 반복 실험
3. **Evaluate**: 평가 자동화 및 품질 측정
4. **Deploy**: 운영 환경 배포 및 통합
5. **Govern**: 전체 시스템 거버넌스 및 모니터링

---

## 🔍 1. 모델 탐색 (Discover)

오늘날 수많은 오픈소스 및 상용 모델이 존재한다. 하지만 그 중 무엇이 우리 애플리케이션에 적합할까?

선택 시 고려할 요소는 다음과 같다:

- **성능** (벤치마크 또는 직접 테스트)
- **지연 시간** (실시간 응답이 중요한 경우)
- **비용** (API 사용료, 인프라 비용)
- **법적·윤리적 문제**

이를 돕기 위한 도구로 **Vertex Model Garden**이 소개된다. 이는 Google 및 파트너의 모델들을 모아둔 **중앙 모델 허브**로, 성능, 사용 사례, 제한 사항 등의 정보를 카드 형태로 제공한다.

---

## 🧪 2. 개발 및 실험 (Develop & Experiment)

### 🔹 프롬프트 기반 개발

기존 ML은 피처 엔지니어링이 중요했다면, 생성형 AI에서는 **프롬프트 엔지니어링**이 핵심이다. 모델 입력의 작은 변화만으로도 출력이 크게 달라지기 때문에, **프롬프트 자체가 데이터이며 동시에 코드**가 된다.

> 🔄 Prompt = Template + User Input → Prompted Model Component

이 구성 요소는 **버전 관리**, **테스트**, **유효성 검사**의 대상이 된다. 백서는 이를 **“prompt-as-data” & “prompt-as-code”**로 정의하며, 이중적 성격을 갖는다고 설명한다.

---

## 🔗 3. 체이닝과 확장 (Chain & Augment)

단일 프롬프트만으로 해결할 수 없는 복잡한 문제를 위해, 모델 컴포넌트들을 **체인(chain)**으로 구성할 수 있다. 대표적인 두 가지 패턴은 다음과 같다:

- **RAG (Retrieval-Augmented Generation)**: 외부 데이터베이스에서 정보 조회 후 모델 입력으로 활용
- **Agents**: LLM이 도구(API, 시스템 등)와 상호작용하며 작업 수행

이 구조에서는 **전체 체인을 하나의 단위**로 보고, **종단 간(end-to-end) 평가** 및 **버전 관리**가 필수적이다. Vertex AI는 이를 위해 LangChain 통합, Vector Search, Agent Builder 등 다양한 도구를 제공한다.

---

## 🛠️ 4. 모델 튜닝 (Tuning & Training)

프롬프트만으로 부족할 때는 모델 자체를 조정해야 한다. 대표적인 접근 방식:

- **SFT (Supervised Fine-Tuning)**: 레이블된 데이터를 활용해 미세조정
- **RLHF (Reinforcement Learning with Human Feedback)**: 인간 피드백을 기반으로 보상 모델을 학습

Vertex AI는 모델 레지스트리, 파이프라인, 실험 관리 기능을 통해 이러한 튜닝 과정을 추적하고 관리할 수 있도록 지원한다.

---

## 📊 5. 평가 (Evaluate)

생성형 AI 평가의 어려움:

- 출력이 복잡하고 비정형
- 정답이 없는 경우가 많음
- 정량 지표(BLEU, ROUGE 등)만으로는 부족

이를 해결하기 위해:

- **맞춤형 평가 기준 정의** (정확성, 일관성, 창의성 등)
- **LLM을 평가자(judge)로 활용** → AutoEval 등

또한 **공격 내성(adversarial robustness)**도 평가 항목으로 포함되어야 한다.

---

## 🚀 배포 및 운영 (Deploy & Monitor)

생성형 AI 시스템은 다음 요소들을 포함한 복합적인 구조를 가진다:

- 프롬프트 템플릿
- 모델 또는 어댑터 레이어
- 외부 API / 데이터 소스
- 체인 구성

운영 시 고려 사항:

- **CI/CD 파이프라인** 구축
- **재현성 보장** (비결정성 문제 대응)
- **버전 관리** (체인, 프롬프트, 외부 데이터)

Vertex AI는 BigQuery, Feature Store 등과의 통합으로 운영 편의성을 높인다.

---

## 🧭 모니터링과 거버넌스

실시간 운영 중 발생 가능한 문제를 탐지하고 대응하기 위한 필수 요소:

- **스큐(skew) 감지**: 개발 시 데이터와 실제 입력의 차이
- **드리프트 감지**: 시간에 따른 사용자 행동 변화
- **엔드-투-엔드 트레이싱**: 에러 발생 위치 파악

또한 Vertex AI의 평가 서비스와 알림 시스템을 통해 **지속적 평가와 대응 체계** 구축 가능하다.

---

## 🤖 Agent Ops: 차세대 생성형 AI 운영

에이전트 기반 시스템은 단순 생성이 아닌 **행동(action)**까지 포함한다. 이로 인해:

- **자율성 증가**
- **다양한 외부 도구와의 상호작용**
- **복잡한 관찰 및 제어 체계** 필요

백서에서는 이를 위한 구성 요소로 다음을 소개한다:

- **Tool Registry**: 에이전트가 사용할 수 있는 도구 목록 중앙 관리
- **Tool Selection 전략**: Generalist / Specialist / Dynamic
- **에이전트 평가**: 단위 테스트부터 운영 지표까지 다단계 측정
- **단기/장기 메모리 관리**: 문맥 유지 및 추적 가능성 강화

---

## 🧩 결론: 플랫폼의 중요성

이 모든 과정을 원활하게 수행하기 위해, 백서는 **Vertex AI**의 역할을 강조한다. Vertex는 다음과 같은 통합 기능을 제공한다:

- 모델 탐색(Model Garden)
- 프롬프트 설계(Generative Studio)
- 데이터 관리(BigQuery, Feature Store)
- 평가 및 거버넌스(Metadata, Datalex)
- Agent Builder 및 Langchain 통합

> **“Vertex AI는 생성형 AI를 프로덕션 수준으로 확장할 수 있는 통합 플랫폼이다.”**

---

## 🧠 생각거리

> 생성형 AI와 Agent Ops의 빠른 발전 속도 속에서, 앞으로 어떤 새로운 MLOps 과제들이 등장할까? 그리고 플랫폼은 어떻게 진화해야 할까?

지금은 단순 모델 성능이 아니라, **전체 시스템을 운영하고 진화시킬 수 있는 능력**이 중요한 시대다.
