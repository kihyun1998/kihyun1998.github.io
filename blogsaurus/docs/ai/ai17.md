---
sidebar_position: 17
---

# 📘 Day 2 정리: Embeddings와 벡터 데이터베이스 완전 정복

> **Kaggle x Google Cloud x DeepMind - Generative AI 집중 과정 (Day 2)**  
> Embeddings의 개념부터 실무 적용까지, 벡터 데이터베이스와 RAG 시스템 설계까지 총정리

---

## 🗂️ 오늘의 아젠다

- Embeddings란?
- 다양한 형태의 Embedding
- 벡터 인덱싱과 검색 알고리즘
- 벡터 DB의 아키텍처적 고려사항
- Retrieval-Augmented Generation(RAG) 시스템에서의 적용
- 최신 연구 및 실제 Google 제품 활용 사례
- 코드랩 소개 및 실습

---

## 🧠 Embedding이란?

> 데이터를 고차원의 의미 공간(semantic space) 상에서 수치 벡터로 표현한 것.

- 주로 텍스트, 이미지, 구조화 데이터 등 다양한 형식을 공통된 벡터 공간으로 변환
- **거리 계산**을 통해 의미 유사성을 비교
- LLM 등 다양한 다운스트림 AI 모델에서 입력 특징으로 활용

### 주요 특징

- 유사한 의미의 데이터는 가까운 벡터로 표현됨
- RAG, 추천 시스템, 이상 탐지 등에 활용 가능

---

## ✍️ Embedding의 다양한 유형

- **텍스트 Embedding**
  - Word2Vec → BERT → Gemini 기반 최신 모델
- **이미지 및 멀티모달 Embedding**
  - 이미지+텍스트 조합 표현
  - DeepMind의 *TIFA* 모델(Tips: Text-Image Fine-grained Awareness) 소개됨
- **구조화/그래프 데이터 Embedding**
  - 비정형 외 다양한 데이터 처리 가능성 확장

---

## 🛠️ Embedding 훈련 방식

- **Dual Encoders + Contrastive Loss**
  - 유사한 쌍을 가깝게, 비유사한 쌍을 멀어지게 학습
- **LLM을 활용한 사전학습 / 데이터 생성**
  - 데이터 품질 개선 + 다국어/멀티모달 학습 가속화

---

## 🔍 벡터 검색 (Vector Search)

> 수십억 개의 벡터에서 빠르게 유사 항목을 찾는 기술

### 핵심 알고리즘

- **HNSW (Hierarchical Navigable Small World)**
- **SCAN (Google 내부 사용, AlloyDB에 탑재)**
  - Approximate Nearest Neighbor(ANN) 기반
  - 약간의 정확도 손실 ↔ 큰 속도 향상

---

## 🏢 벡터 데이터베이스 아키텍처

### 일반 DB vs 벡터 DB

| 항목 | 통합형 DB (예: AlloyDB) | 전용 벡터 DB (예: Vertex AI Vector Search) |
|------|--------------------------|--------------------------------------------|
| 구조화 데이터 활용 | 뛰어남 | 별도 연결 필요 |
| 성능 | SCAN 내장으로 우수 | ANN 최적화, 고성능 |
| 일관성, 트랜잭션 | 강력함 | 제한적일 수 있음 |
| 비용 | 상대적으로 절감 가능 | 고비용 메모리 기반 |

### 하이브리드 구성 고려사항

- 필터 조건 검색 (가격, 색상 등) vs 비정형 유사도 검색
- SQL 기반 조인, 필터, 정렬 등을 하나의 질의로 처리 가능
- 시스템 간 데이터 정합성, ETL 비용 고려

---

## 🔄 최신 Embedding 전환과 관리 전략

- **Embedding 모델 업그레이드 시 전체 재생성 필요**
  - 서로 다른 모델 간 호환 불가
- 연구 중: 기존 벡터를 새 임베딩으로 **효율적 변환**하는 기술
- **동일 모델로 쿼리/문서 Embedding 유지 필수**
- 평가 지표: precision, recall + latency, throughput

---

## 🧩 RAG(Retrieval-Augmented Generation) 시스템 팁

- 검색/생성 일관성 위해 동일 Embedding 모델 사용
- **하이브리드 검색** 추천:
  - 키워드 매칭 (sparse) + 의미 검색 (dense) 결합
- **Reranking**, **Metadata Filtering**, **BM25** 결합 사용
- **실시간성** 요구 시: No-index RAG, 최신 API 활용 가능

---

## 💼 엔터프라이즈 적용 전략 (CTO 인사이트)

### 임베딩 도입의 기대 효과

- 다양한 형태의 데이터(텍스트, 이미지 등) 검색 가능
- 정밀한 추천, 의미 기반 분류 가능
- 데이터 아키텍처의 패러다임 변화

### 도입 시 도전 과제

- 비용, 표준화 부재, 인재 확보
- 기존 시스템과의 통합 어려움
- 데이터 거버넌스, 보안 이슈

---

## 🧪 코드랩 요약

### 1. RAG 파이프라인 만들기
- Chroma DB + Gemini API로 간단한 RAG 구현

### 2. Embedding 유사도 시각화
- Heatmap으로 문장 간 의미 유사도 시각 확인

### 3. Embedding을 분류 모델 특징으로 활용
- 사전학습된 임베딩 → 분류기 위에 추가 층 학습

---

## 🎯 퀴즈 요약 (복습 체크)

- ❌ Rule-based 시스템은 임베딩 부적합
- ✅ SCAN은 고차원에서 속도/정확도 우수
- ❌ Bag-of-Words는 순서/의미 무시
- ✅ RAG에서 임베딩 + 키워드 혼합 추천
- ✅ LSH는 유사 아이템을 hash bucket에 그룹화

---

## 📝 마무리

Day 2는 임베딩과 벡터 DB의 이론부터 실전 응용까지 아우르는 강의였습니다. RAG 시스템 구축, 성능 평가, 최신 모델 적용 전략까지 다룬 만큼, 오늘의 내용을 기반으로 여러분의 AI 시스템에 강력한 검색 및 문맥 처리 능력을 추가해 보세요!
