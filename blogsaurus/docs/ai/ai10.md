---
sidebar_position: 10
---

# 🎧 Whitepaper Companion Podcast 요약: Foundational LLMs & Text Generation
---

## 📑 목차
1. [소개 및 목표](#소개-및-목표)
2. [Transformer 구조 소개](#transformer-구조-소개)
3. [Transformer 구성요소 상세 설명](#transformer-구성요소-상세-설명)
4. [Decoder-only 모델의 등장과 장점](#decoder-only-모델의-등장과-장점)
5. [Mixture of Experts (MoE)](#mixture-of-experts-moe)
6. [LLM 발전 연대기](#llm-발전-연대기)
7. [파인튜닝과 인간 피드백](#파인튜닝과-인간-피드백)
8. [Parameter-Efficient Fine-Tuning](#parameter-efficient-fine-tuning)
9. [프롬프트 엔지니어링 & 샘플링 기법](#프롬프트-엔지니어링--샘플링-기법)
10. [LLM 평가 방법](#llm-평가-방법)
11. [추론 속도 최적화 기법](#추론-속도-최적화-기법)
12. [실제 활용 사례](#실제-활용-사례)
13. [마무리 및 미래 전망](#마무리-및-미래-전망)

---

## 소개 및 목표

- 본 팟캐스트는 **LLM이 어떻게 구성되고 작동하는지**, **어떻게 발전해왔는지**, **어떻게 평가하고 효율화하는지**를 다룬다.
- Transformer 구조부터 최신 모델들까지의 진화를 설명하며, 실제 활용 사례와 미래 전망도 논의한다.

---

## Transformer 구조 소개

- Transformer는 2017년 구글의 **번역 프로젝트**에서 시작되었다.
- 초기 구조는 **Encoder + Decoder** 형태였다.
  - **Encoder**: 입력 문장 (예: 프랑스어)을 벡터로 요약.
  - **Decoder**: 그 벡터를 바탕으로 출력 문장 (예: 영어)을 생성.
- 문장은 **토큰(token)** 단위로 처리되며, 이는 단어 하나 또는 단어의 일부일 수 있다.

---

## Transformer 구성요소 상세 설명

### 1. **토크나이징 및 임베딩**
- 문장을 미리 정해진 **vocabulary**에 따라 **토큰**으로 나눈다.
- 각 토큰은 의미를 담은 **임베딩 벡터**로 변환된다.

### 2. **Positional Encoding**
- Transformer는 입력을 **동시에 병렬 처리**하므로, 단어 순서를 알 수 없음.
- 그래서 **Positional Encoding**을 추가:
  - **Sinusoidal 방식** 또는 **학습된 방식(learned)** 존재.
  - 문장 구조 이해에 영향을 줄 수 있음.

### 3. **Multi-Head Self Attention**
- 문장 내 단어들 간의 관계를 파악하기 위한 핵심 메커니즘.
- 예시 문장:  
  > “The tiger jumped out of a tree to get a drink because it was thirsty.”  
  여기서 “it”이 “tiger”를 의미한다는 것을 **self-attention**이 파악.
- 각 단어는 **Query, Key, Value** 벡터를 갖는다.
  - Query: "나는 누구와 관련 있지?"
  - Key: 단어의 정체성 정보
  - Value: 실제 정보  
- Query와 Key를 내적하여 **attention score** 계산 → softmax → 각 단어가 다른 단어에 얼마만큼 집중할지 결정.
- 이 모든 연산은 **행렬 단위로 병렬 처리**된다.
- **Multi-head** 구조로 각 head는 서로 다른 관계(문법적, 의미적 등)를 학습한다.

### 4. **Layer Normalization & Residual Connection**
- LayerNorm: 각 층의 활성값을 안정적으로 유지
- Residual: 입력을 다음 출력에 더해줌 → **정보 손실 방지** + **학습 안정화**

### 5. **Feed Forward Layer**
- 각 토큰에 대해 독립적으로 적용되는 2개의 선형 변환 + 비선형 활성함수 (ReLU, GeLU 등)

---

## Decoder-only 모델의 등장과 장점

- 텍스트 생성에 집중한 모델들은 **Decoder-only 구조**를 채택 (예: GPT 계열).
- **Masked Self-Attention** 사용:
  - 다음 토큰을 예측할 때 이전 토큰만 참고할 수 있게 제한함 → 사람이 글 쓰는 방식과 유사.

---

## Mixture of Experts (MoE)

- 초대형 모델의 효율성을 높이기 위한 방식.
- 여러 **전문 sub-model (expert)**을 구성하고, 입력마다 일부만 활성화.
- **Gating network**가 어떤 expert를 쓸지 결정.
- 성능은 유지하면서도 연산량을 줄임.

---

## LLM 발전 연대기

| 연도 | 모델 | 특징 |
|------|------|------|
| 2018 | GPT-1 | Decoder-only, BookCorpus, 반복 문제 |
| 2018 | BERT | Encoder-only, 언어 이해에 특화 |
| 2019 | GPT-2 | WebText, zero-shot 가능 |
| 2020+ | GPT-3 | 175B 파라미터, few-shot 가능 |
| 이후 | GPT-3.5, GPT-4 | 코드 이해, 멀티모달 기능 |
| 2021 | LaMDA (Google) | 대화에 특화 |
| 2021 | Gopher (DeepMind) | 고품질 데이터, 지식 기반 태스크 |
| 2022 | Chinchilla (DeepMind) | 파라미터 대비 학습 데이터 증가 |
| 2022 | PaLM | Google Pathways, 확장성 개선 |
| 2023 | PaLM 2 | 적은 파라미터로 더 나은 성능 |
| 2024 | Gemini | 멀티모달, 대용량 컨텍스트, MoE |
| 2024 | Gemma 1, 2 | 경량, 오픈소스, LLaMA 3보다 빠름 |
| - | LLaMA 1/2/3 | Meta, 다국어, 비전 모델 포함 |
| - | Mistral Mixtral | Sparse MoE, 수학 및 다국어 우수 |
| - | DeepSeek R1 | RL 기법, OpenAI 01 수준 |
| - | 기타 | Qwen, Yi, Grok 등 다양한 오픈모델 |

---

## 파인튜닝과 인간 피드백

- **Pretraining**: 라벨 없는 방대한 텍스트로 기본 언어 능력 학습.
- **Fine-tuning**: 특정 태스크용 라벨된 소규모 데이터로 특화.
- **SFT (Supervised Fine-Tuning)**:
  - Prompt-Response 쌍으로 학습 → 행동 패턴 및 안전성 강화
- **RLHF (Reinforcement Learning from Human Feedback)**:
  - 사람의 선호를 학습한 **Reward Model**을 이용하여 LLM을 강화학습

---

## Parameter-Efficient Fine-Tuning

- **전체 모델 파인튜닝은 비싸다** → 일부 파라미터만 조정하는 기법들 등장

| 기법 | 설명 |
|------|------|
| Adapter | 중간 층에 작은 모듈 삽입하여 거기만 학습 |
| LoRA | weight 변화를 저랭크 행렬로 근사 |
| QLoRA | LoRA + 양자화(quantization) |
| Soft Prompting | 입력 앞에 학습된 벡터 추가 |

---

## 프롬프트 엔지니어링 & 샘플링 기법

### 🧠 프롬프트 기법
- **Zero-shot**: 예시 없이 직접 질문
- **Few-shot**: 예시 몇 개 제공
- **Chain-of-Thought**: 추론 과정을 단계별로 보여줌

### 🎲 샘플링 기법
| 기법 | 특징 |
|------|------|
| Greedy | 항상 가장 확률 높은 토큰 선택 → 반복 가능성 ↑ |
| Random Sampling | 창의성 ↑, 오류 가능성 ↑ |
| Temperature | 무작위성 조절 (↑면 창의성 ↑) |
| Top-k | 확률 높은 k개 중에서 샘플링 |
| Top-p (Nucleus) | 누적 확률이 p 이하인 토큰 중에서 선택 |
| Best-of-n | 여러 개 생성 후 가장 좋은 것 선택 |

---

## LLM 평가 방법

- **정량 평가**: BLEU, ROUGE 등 → 정답에 얼마나 가까운지
- **정성 평가**: 사람 리뷰어가 유창성, 일관성, 창의성 등 평가
- **AI 평가자**: LLM이 다른 LLM의 출력을 채점 (Generative, Discriminative, Reward 모델 등)
- **다중 기준 평가**: 정확도, 유용성, 스타일 등 맞춤 평가 기준 설정
- **멀티모달 평가**: 텍스트, 이미지, 영상 각각 따로 평가 필요

---

## 추론 속도 최적화 기법

| 범주 | 기법 | 설명 |
|------|------|------|
| 🔄 출력 변화 있음 | Quantization | 연산을 8비트/4비트로 줄여 속도 증가 |
|  | Distillation | 작은 모델이 큰 모델 모방 |
| ✅ 출력 유지 | Flash Attention | 데이터 이동 최소화, 병렬화 향상 |
|  | Prefix Caching | 대화 컨텍스트 부분 결과 캐싱 |
|  | Speculative Decoding | 빠른 Drafter 모델 예측 → 검증 후 건너뜀 |
| 병렬화 | Batching / Parallelization | 다수 요청 동시 처리 or 연산 분산 |

---

## 실제 활용 사례

- **코딩**: 생성, 리팩토링, 디버깅, 문서화, 코드 번역 등 (예: AlphaCode 2)
- **수학/과학**: FundSearch, AlphaGeometry → 수학적 발견 보조
- **번역/요약/질문응답**: 자연스럽고 정확한 결과 제공
- **대화/창작**: 광고, 대본, 창의적 글쓰기 등
- **의료/법률/감정 분석**: 진단 보조, 문서 분석, 고객 피드백 분석
- **LLM 평가자 역할**: 다른 모델의 출력을 채점
- **데이터 분석**: 대규모 데이터에서 인사이트 추출

---

## 마무리 및 미래 전망

- Transformer 기반 구조는 여전히 핵심.
- LLM은 빠르게 발전 중이며, **멀티모달 기능**과 **대규모 컨텍스트 윈도우**가 핵심 경쟁 요소.
- **다양한 응용 분야**에서 LLM의 활용은 계속 확장될 것으로 기대됨.
- 다음 세대 LLM으로 무엇이 가능해질지, 어떤 과제가 있는지에 대한 청취자 의견 요청으로 마무리.

---