"use strict";(self.webpackChunkblogsaurus=self.webpackChunkblogsaurus||[]).push([[31367],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>_});var a=n(67294);function l(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){l(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,l=function(e,t){if(null==e)return{};var n,a,l={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(l[n]=e[n]);return l}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(l[n]=e[n])}return l}var p=a.createContext({}),s=function(e){var t=a.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},d=function(e){var t=s(e.components);return a.createElement(p.Provider,{value:t},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var n=e.components,l=e.mdxType,r=e.originalType,p=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),u=s(n),c=l,_=u["".concat(p,".").concat(c)]||u[c]||m[c]||r;return n?a.createElement(_,i(i({ref:t},d),{},{components:n})):a.createElement(_,i({ref:t},d))}));function _(e,t){var n=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var r=n.length,i=new Array(r);i[0]=c;var o={};for(var p in t)hasOwnProperty.call(t,p)&&(o[p]=t[p]);o.originalType=e,o[u]="string"==typeof e?e:l,i[1]=o;for(var s=2;s<r;s++)i[s]=n[s];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},29743:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>m,frontMatter:()=>r,metadata:()=>o,toc:()=>s});var a=n(87462),l=(n(67294),n(3905));const r={sidebar_position:17},i="[LLM] 17. \uc0ac\uc804 \ud559\uc2b5",o={unversionedId:"llm/llm17",id:"llm/llm17",title:"[LLM] 17. \uc0ac\uc804 \ud559\uc2b5",description:"---",source:"@site/docs/llm/llm17.md",sourceDirName:"llm",slug:"/llm/llm17",permalink:"/docs/llm/llm17",draft:!1,tags:[],version:"current",sidebarPosition:17,frontMatter:{sidebar_position:17},sidebar:"aiSidebar",previous:{title:"[LLM] 16. \ud559\uc2b5 \ud3c9\uac00",permalink:"/docs/llm/llm16"}},p={},s=[{value:"\ub370\uc774\ud130 \uc900\ube44",id:"\ub370\uc774\ud130-\uc900\ube44",level:2},{value:"\uc778\ucf54\ub529",id:"\uc778\ucf54\ub529",level:2},{value:"\uc778\ucf54\ub529 \ud568\uc218",id:"\uc778\ucf54\ub529-\ud568\uc218",level:3},{value:"\ud3c9\uac00",id:"\ud3c9\uac00",level:2},{value:"\ud750\ub984",id:"\ud750\ub984",level:3},{value:"\ud559\uc2b5",id:"\ud559\uc2b5",level:2},{value:"\ud750\ub984 \uc124\uba85",id:"\ud750\ub984-\uc124\uba85",level:3},{value:"\ud559\uc2b5 \uc9c4\ud589",id:"\ud559\uc2b5-\uc9c4\ud589",level:3}],d={toc:s},u="wrapper";function m(e){let{components:t,...r}=e;return(0,l.kt)(u,(0,a.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"llm-17-\uc0ac\uc804-\ud559\uc2b5"},"[LLM]"," 17. \uc0ac\uc804 \ud559\uc2b5"),(0,l.kt)("hr",null),(0,l.kt)("p",null,"\uc0ac\uc804 \ud559\uc2b5\uc744 \uc9c4\ud589\ud574\ubd24\uc2b5\ub2c8\ub2e4."),(0,l.kt)("h2",{id:"\ub370\uc774\ud130-\uc900\ube44"},"\ub370\uc774\ud130 \uc900\ube44"),(0,l.kt)("hr",null),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'# \ud6c8\ub828 \ub370\uc774\ud130\uc640 \uac80\uc99d \ub370\uc774\ud130 \uc900\ube44\nall_data = [\n    ("What is the capital of France?", "The capital of France is Paris."),\n    ("What is the capital of Germany?", "The capital of Germany is Berlin."),\n    ("How are you?", "I am fine, thank you. And you?"),\n    ("What is 2 + 2?", "2 + 2 equals 4."),\n    ("Who wrote Harry Potter?", "J.K. Rowling wrote Harry Potter."),\n    ("What is the tallest mountain?", "Mount Everest is the tallest mountain."),\n    ("When was the first computer invented?", "The first electronic computer was invented in the 1940s."),\n    ("What is the boiling point of water?", "Water boils at 100 degrees Celsius at sea level."),\n    ("Who painted the Mona Lisa?", "Leonardo da Vinci painted the Mona Lisa."),\n    ("What is the capital of Japan?", "The capital of Japan is Tokyo."),\n]\n')),(0,l.kt)("p",null,"\uc774\ub7f0 \ud6c8\ub828\ub370\uc774\ud130\ub85c \ud559\uc2b5\ud558\ub824 \ud588\uc2b5\ub2c8\ub2e4."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'def prepare_training_data(data):\n    """\uac01 \uc751\ub2f5 \ub05d\uc5d0 EOS \ud1a0\ud070\uc744 \uba85\uc2dc\uc801\uc73c\ub85c \ucd94\uac00"""\n    formatted_data = []\n    for question, answer in data:\n        # EOS \ud1a0\ud070\uc774 \uba85\uc2dc\uc801\uc73c\ub85c \ucd94\uac00\ub41c \ub2f5\ubcc0\n        formatted_answer = answer + tokenizer.eos_token\n        formatted_data.append((question, formatted_answer))\n    return formatted_data\n\n\ntokenizer = GPT2Tokenizer.from_pretrained("gpt2")\n\n\n# \ub370\uc774\ud130\ub97c \ud6c8\ub828 \uc138\ud2b8\uc640 \uac80\uc99d \uc138\ud2b8\ub85c \ubd84\ud560 (80% \ud6c8\ub828, 20% \uac80\uc99d)\nrandom.seed(42)  # \uc7ac\ud604\uc131\uc744 \uc704\ud55c \uc2dc\ub4dc \uc124\uc815\nrandom.shuffle(all_data)\ntrain_size = int(0.8 * len(all_data))\ntraining_data = all_data[:train_size]\nvalidation_data = all_data[train_size:]\n\ntraining_data = prepare_training_data(training_data)\nvalidation_data = prepare_training_data(validation_data)\n')),(0,l.kt)("p",null,"\uc774 \ubb38\uc7a5\ub4e4\uc744 \ud559\uc2b5\ud560 \ub54c \uadf8\ub0e5 \ub4a4\uc5d0 EOS\ub97c \ubd99\uc5ec\uc11c \ud559\uc2b5\ud558\uae30\ub85c \ud588\uc2b5\ub2c8\ub2e4."),(0,l.kt)("h2",{id:"\uc778\ucf54\ub529"},"\uc778\ucf54\ub529"),(0,l.kt)("hr",null),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'def encode_text(full_text):\n    """\n    \ud14d\uc2a4\ud2b8\ub97c \uc778\ucf54\ub529\ud558\uace0 \uc785\ub825(input)\uacfc \ud0c0\uac9f(target) \uc2dc\ud000\uc2a4\ub85c \ubd84\ub9ac\n    \uc785\ub825: \uc2dc\ud000\uc2a4\uc758 \ucc98\uc74c\ubd80\ud130 \ub9c8\uc9c0\ub9c9 \ud1a0\ud070 \uc774\uc804\uae4c\uc9c0\n    \ud0c0\uac9f: \uc2dc\ud000\uc2a4\uc758 \ub450 \ubc88\uc9f8 \ud1a0\ud070\ubd80\ud130 \ub05d\uae4c\uc9c0\n    """\n    encoded = tokenizer.encode(full_text, return_tensors="pt")\n    input_ids = encoded[:, :-1]  # \ub9c8\uc9c0\ub9c9 \ud1a0\ud070 \uc81c\uc678\n    target_ids = encoded[:, 1:]  # \uccab \ubc88\uc9f8 \ud1a0\ud070 \uc81c\uc678\n    return input_ids, target_ids\n\n')),(0,l.kt)("p",null,"\ud559\uc2b5\uc744 \uc704\ud55c \uc778\ucf54\ub529 \ud568\uc218\uc785\ub2c8\ub2e4."),(0,l.kt)("h3",{id:"\uc778\ucf54\ub529-\ud568\uc218"},"\uc778\ucf54\ub529 \ud568\uc218"),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"encode_text")," \ud568\uc218\ub294 \uc785\ub825 \uc2dc\ud000\uc2a4\uc640 \uc815\ub2f5 \uc2dc\ud000\uc2a4\ub97c \ub9cc\ub4dc\ub294 \uac83\uacfc \uac19\uc2b5\ub2c8\ub2e4."),(0,l.kt)("p",null,'"Hello World"\uac00 \ub4e4\uc5b4\uc654\ub2e4\uace0 \uc608\ub97c \ub4e4\uace0 \uc544\ub798\ucc98\ub7fc \uac12\uc774 \uc0dd\uc131\ub410\ub2e4\uace0 \uac00\uc815\ud574\ubd05\uc2dc\ub2e4.'),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'encoded =tokenizer.encode("Hello world", return_tensors="pt")\n# encoded = [[101, 7592, 2088, 102]]\n')),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"101")," -> \uc2dc\uc791 \ud1a0\ud070(CLS)"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"1234"),' -> "Hello"\uc758 \ud1a0\ud070 ID'),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"5678"),' -> "World"\uc758 \ud1a0\ud070 ID'),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"102")," -> \uc885\ub8cc \ud1a0\ud070(SEP)")),(0,l.kt)("p",null,"\uc785\ub2c8\ub2e4. \uadf8\ub7fc \uc544\ub798\ucc98\ub7fc \ub418\uaca0\uc8e0?"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-text"},"input_ids = [101,1234,5678]\ntarget_ids = [1234,5678,102]\n")),(0,l.kt)("p",null,"\uc5ec\uae30\uae4c\uc9c4 \uc774\ud574\uac00 \ub429\ub2c8\ub2e4. \uadf8\ub7fc. \uadf8\ub798\uc11c \ubb50? \ub77c\ub294 \uc758\ubb38\uc774 \ub4e4 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. \ubb50\ub0d0\uba74"),(0,l.kt)("p",null,"input_ids\uac00 target_ids\ub97c \ub9de\ucdb0\uc57c\ud558\ub294 \uac81\ub2c8\ub2e4. \ud45c\ub85c \ubcf4\uba74 \uc774\ud574\uac00 \ube60\ub978\ub370"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Step"),(0,l.kt)("th",{parentName:"tr",align:null},"Input"),(0,l.kt)("th",{parentName:"tr",align:null},"Target"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"1"),(0,l.kt)("td",{parentName:"tr",align:null},"101"),(0,l.kt)("td",{parentName:"tr",align:null},"1234")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"2"),(0,l.kt)("td",{parentName:"tr",align:null},"101, 1234"),(0,l.kt)("td",{parentName:"tr",align:null},"5678")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"3"),(0,l.kt)("td",{parentName:"tr",align:null},"101, 1234, 5678"),(0,l.kt)("td",{parentName:"tr",align:null},"102")))),(0,l.kt)("p",null,"\uc774\ub7f0\uc2dd\uc73c\ub85c Input\uc774 \ub4e4\uc5b4\uc654\uc744 \ub54c Target\uc744 \uc608\uce21\ud558\ub3c4\ub85d \ud559\uc2b5\uc2dc\ud0a8\ub2e4\uace0 \ud569\ub2c8\ub2e4."),(0,l.kt)("p",null,"\uc989. Autoregressive\ubaa8\ub378\uc774\uae30 \ub54c\ubb38\uc5d0 \ud55c \ub2e8\uacc4 \uc529 \uc608\uce21\ud558\uba74\uc11c \ud559\uc2b5 \ud558\ub294 \uac81\ub2c8\ub2e4."),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"Hello"),"\uac00 \ub4e4\uc5b4\uc624\uba74 ",(0,l.kt)("inlineCode",{parentName:"p"},"World"),"\uac00 \uc62c\uac78 \uc608\uc0c1\ud558\uace0 ",(0,l.kt)("inlineCode",{parentName:"p"},"Hello World"),"\uac00 \uc644\uc131\ub418\uba74 \uc885\ub8cc\ud1a0\ud070\uc744 \uc608\uc0c1\ud558\ub294 \uac81\ub2c8\ub2e4."),(0,l.kt)("h2",{id:"\ud3c9\uac00"},"\ud3c9\uac00"),(0,l.kt)("hr",null),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'def evaluate(data_set):\n    """\uac80\uc99d \ub370\uc774\ud130\uc5d0 \ub300\ud55c \uc190\uc2e4 \uacc4\uc0b0"""\n    model.eval()  # \ubaa8\ub378\uc744 \ud3c9\uac00 \ubaa8\ub4dc\ub85c \uc124\uc815\n    total_loss = 0\n    \n    with torch.no_grad():  # \uadf8\ub798\ub514\uc5b8\ud2b8 \uacc4\uc0b0 \ube44\ud65c\uc131\ud654\n        for input_text, target_text in data_set:\n            # \uc785\ub825\uacfc \ud0c0\uac9f\uc744 \ud558\ub098\uc758 \uc2dc\ud000\uc2a4\ub85c \uc5f0\uacb0\n            full_text = input_text + " " + target_text\n            input_ids, target_ids = encode_text(full_text)\n            input_ids, target_ids = input_ids.to(device), target_ids.to(device)\n            \n            # \ubaa8\ub378 \uc608\uce21\n            logits = model(input_ids)\n            \n            # \uc190\uc2e4 \uacc4\uc0b0\n            loss = criterion(logits.reshape(-1, logits.size(-1)), target_ids.reshape(-1))\n            total_loss += loss.item()\n    \n    # \ud3c9\uade0 \uc190\uc2e4 \ubc18\ud658\n    return total_loss / len(data_set)\n')),(0,l.kt)("p",null,"\ud6c8\ub828\uc5d0 \ub300\ud55c \uc190\uc2e4\uc744 \ud3c9\uac00\ud558\ub294 \ucf54\ub4dc\uc785\ub2c8\ub2e4."),(0,l.kt)("p",null,"no_grad\ub85c \ud558\ub294 \uc774\uc720\ub294 \uae30\uc6b8\uae30\uac00 \ud544\uc694\uc5c6\uc5b4\uc11c \uc785\ub2c8\ub2e4."),(0,l.kt)("h3",{id:"\ud750\ub984"},"\ud750\ub984"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'    full_text = input_text + " " + target_text\n    input_ids, target_ids = encode_text(full_text)\n    input_ids, target_ids = input_ids.to(device), target_ids.to(device)\n')),(0,l.kt)("p",null,"\uc9c8\ubb38\uacfc \uc815\ub2f5\uc744 \uc77c\ub2e8 \ud569\uccd0\ubd05\ub2c8\ub2e4. (\ud559\uc2b5 \ud560 \uc218 \uc788\ub3c4\ub85d)\n\uadf8\ub9ac\uace0 tokenid\ub85c \ub9cc\ub4ed\ub2c8\ub2e4."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"    # \ubaa8\ub378 \uc608\uce21\n    logits = model(input_ids)\n")),(0,l.kt)("p",null,"\uc785\ub825 \ud1a0\ud070\uc544\uc774\ub514\ub97c \ubaa8\ub378\uc5d0 \ub123\uc5b4\uc11c \uc608\uce21\uc744 \uc9c4\ud589\ud569\ub2c8\ub2e4."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"    # \uc190\uc2e4 \uacc4\uc0b0\n    loss = criterion(logits.reshape(-1, logits.size(-1)), target_ids.reshape(-1))\n    total_loss += loss.item()\n")),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"CrossEntropyLoss"),"\ub85c \uc190\uc2e4\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4. \uacc4\uc0b0\ud55c \uc190\uc2e4\uc758 total\uc744 \uad6c\ud574\ub193\uace0 \ud3c9\uade0\uc744 \ubc18\ud658\ud569\ub2c8\ub2e4."),(0,l.kt)("h2",{id:"\ud559\uc2b5"},"\ud559\uc2b5"),(0,l.kt)("hr",null),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n\n# \ud559\uc2b5 \uc2dc\uc791\nnum_epochs = 10  # \uc5d0\ud3ed \uc218 \uc99d\uac00\nbest_val_loss = float(\'inf\')\nearly_stopping_counter = 0\nearly_stopping_patience = 5  # 5\ubc88 \uc5f0\uc18d\uc73c\ub85c \uac1c\uc120\uc774 \uc5c6\uc73c\uba74 \uc870\uae30 \uc885\ub8cc\n\nprint("\ud559\uc2b5 \uc2dc\uc791...")\nfor epoch in range(num_epochs):\n    model.train()  # \ubaa8\ub378\uc744 \ud6c8\ub828 \ubaa8\ub4dc\ub85c \uc124\uc815\n    train_loss = 0\n    \n    # tqdm\uc73c\ub85c \uc9c4\ud589 \uc0c1\ud669 \ud45c\uc2dc\n    progress_bar = tqdm(training_data, desc=f"Epoch {epoch+1}/{num_epochs}")\n    for input_text, target_text in progress_bar:\n        # \uc785\ub825\uacfc \ud0c0\uac9f\uc744 \ud558\ub098\uc758 \uc2dc\ud000\uc2a4\ub85c \uc5f0\uacb0\n        full_text = input_text + " " + target_text\n        input_ids, target_ids = encode_text(full_text)\n        input_ids, target_ids = input_ids.to(device), target_ids.to(device)\n        \n        # \uadf8\ub798\ub514\uc5b8\ud2b8 \ucd08\uae30\ud654\n        optimizer.zero_grad()\n        \n        # \ubaa8\ub378 \uc608\uce21\n        logits = model(input_ids)\n        \n        # \uc190\uc2e4 \uacc4\uc0b0\n        loss = criterion(logits.reshape(-1, logits.size(-1)), target_ids.reshape(-1))\n        \n        # \uc5ed\uc804\ud30c \ubc0f \ucd5c\uc801\ud654\n        loss.backward()\n        optimizer.step()\n        \n        # \uc190\uc2e4 \uae30\ub85d\n        train_loss += loss.item()\n        progress_bar.set_postfix({"train_loss": f"{loss.item():.4f}"})\n    \n    # \ud3c9\uade0 \ud6c8\ub828 \uc190\uc2e4 \uacc4\uc0b0\n    avg_train_loss = train_loss / len(training_data)\n    train_losses.append(avg_train_loss)\n    \n    # \uac80\uc99d \ub370\uc774\ud130\uc5d0 \ub300\ud55c \ud3c9\uac00\n    val_loss = evaluate(validation_data)\n    val_losses.append(val_loss)\n    \n    # \uacb0\uacfc \ucd9c\ub825\n    print(f"Epoch {epoch+1}/{num_epochs}, \ud6c8\ub828 \uc190\uc2e4: {avg_train_loss:.4f}, \uac80\uc99d \uc190\uc2e4: {val_loss:.4f}")\n    \n    # \uc870\uae30 \uc885\ub8cc \uac80\uc0ac\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        early_stopping_counter = 0\n        # \ucd5c\uc0c1\uc758 \ubaa8\ub378 \uc800\uc7a5\n        torch.save(model.state_dict(), "best_model.pt")\n        print(f"\u2705 \uac80\uc99d \uc190\uc2e4 \uac1c\uc120! \ubaa8\ub378 \uc800\uc7a5 (\uac80\uc99d \uc190\uc2e4: {val_loss:.4f})")\n    else:\n        early_stopping_counter += 1\n        print(f"\uac80\uc99d \uc190\uc2e4 \uac1c\uc120 \uc5c6\uc74c ({early_stopping_counter}/{early_stopping_patience})")\n        \n    if early_stopping_counter >= early_stopping_patience:\n        print(f"\uc870\uae30 \uc885\ub8cc: {early_stopping_patience}\ubc88 \uc5f0\uc18d\uc73c\ub85c \uac80\uc99d \uc190\uc2e4 \uac1c\uc120 \uc5c6\uc74c")\n        break\n')),(0,l.kt)("p",null,"\ud559\uc2b5 \uc2dc\ud0a4\ub294 \ucf54\ub4dc\uc785\ub2c8\ub2e4."),(0,l.kt)("h3",{id:"\ud750\ub984-\uc124\uba85"},"\ud750\ub984 \uc124\uba85"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"optimizer"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n")),(0,l.kt)("p",null,"optimizer\ub97c \uc120\uc5b8\ud569\ub2c8\ub2e4. \uac00\uc911\uce58 \uc5c5\ub370\uc774\ud2b8\uc5d0 \uc0ac\uc6a9\ub429\ub2c8\ub2e4."),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"epoch"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"num_epochs = 10\n\nfor epoch in range(num_epochs):\n    ...\n\n")),(0,l.kt)("p",null,"epoch \uc218 \ub9cc\ud07c \ud559\uc2b5\uc744 \ubc18\ubcf5\ud569\ub2c8\ub2e4."),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"train mode"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"model.train()\n")),(0,l.kt)("p",null,"model\uc744 \ud559\uc2b5\uc6a9\uc73c\ub85c \ub9cc\ub4ed\ub2c8\ub2e4."),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"tqdm"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'progress_bar = tqdm(training_data, desc=f"Epoch {epoch+1}/{num_epochs}")\n')),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"tqdm"),"\uc740 ",(0,l.kt)("inlineCode",{parentName:"p"},"taquddum"),"\uc758 \uc57d\uc790\ub85c \uc9c4\ud589\uc774\ub77c\ub294 \ub73b\uc744 \uac00\uc9c4 \ud568\uc218\uc778\ub370 \uc9c4\ud589\uc0ac\ud56d\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc900\ub2e4."),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"get token id"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'    # \uc785\ub825\uacfc \ud0c0\uac9f\uc744 \ud558\ub098\uc758 \uc2dc\ud000\uc2a4\ub85c \uc5f0\uacb0\n    full_text = input_text + " " + target_text\n    input_ids, target_ids = encode_text(full_text)\n    input_ids, target_ids = input_ids.to(device), target_ids.to(device)\n')),(0,l.kt)("p",null,"full_text\ub97c \ub9cc\ub4e4\uace0 token id\ub97c \ubc1b\uc544\uc624\ub294 \ucf54\ub4dc\uc774\ub2e4."),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"zero grad"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"    # \uadf8\ub798\ub514\uc5b8\ud2b8 \ucd08\uae30\ud654\n    optimizer.zero_grad()\n")),(0,l.kt)("p",null,"\uc774\uc804 \uae30\uc6b8\uae30\ub97c \ucd08\uae30\ud654 \uc2dc\ucf1c\uc8fc\ub294 \ud568\uc218\uc778\ub370 \uc774\uac78 \ud574\uc918\uc57c \ub2e4\uc74c \ud559\uc2b5 case\uc5d0 \uc601\ud5a5\uc774 \uac00\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4."),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"get loss"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"    # \ubaa8\ub378 \uc608\uce21\n    logits = model(input_ids)\n    \n    # \uc190\uc2e4 \uacc4\uc0b0\n    loss = criterion(logits.reshape(-1, logits.size(-1)), target_ids.reshape(-1))\n")),(0,l.kt)("p",null,"\ubaa8\ub378 \uc608\uce21 \ubc0f \uc190\uc2e4 \uacc4\uc0b0\uc778\ub370 \ub118\uc5b4\uac08\uac8c\uc694"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"backward"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"    loss.backward()\n")),(0,l.kt)("p",null,"\uac00\uc911\uce58\ub97c \uacc4\uc0b0\ud558\ub294 \ud568\uc218\uc785\ub2c8\ub2e4."),(0,l.kt)("h3",{id:"\ud559\uc2b5-\uc9c4\ud589"},"\ud559\uc2b5 \uc9c4\ud589"),(0,l.kt)("p",null,"\ud559\uc2b5\uc744 \uc9c4\ud589\ud588\uc2b5\ub2c8\ub2e4."),(0,l.kt)("p",null,"\uc190\uc2e4 \ud568\uc218\ub294 \ub2e4\uc74c\uacfc \uac19\uc774 \uadf8\ub824\uc9c0\ub354\ub77c\uad6c\uc694"),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"alt text",src:n(68747).Z,width:"1000",height:"600"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-text"},"\ud83d\udcac \uc785\ub825: What is the capital of France?\n\ud83d\udcdd \ucd9c\ub825: The capital of Japan is Tokyo.\n\n\ud83d\udcac \uc785\ub825: How are you?\n\ud83d\udcdd \ucd9c\ub825: I am fine, thank you. And you?\n\n\ud83d\udcac \uc785\ub825: Who wrote Harry Potter?\n\ud83d\udcdd \ucd9c\ub825: J.K. Rowling wrote Harry Potter.\n")),(0,l.kt)("p",null,"\ub2f5\ub3c4 \uc798 \uc8fc\uace0 \ubc1b\ub294 \ubaa8\uc2b5\uc785\ub2c8\ub2e4."))}m.isMDXComponent=!0},68747:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/loss_graph-044abc35e82b8ba7c061181060d6a2e9.png"}}]);